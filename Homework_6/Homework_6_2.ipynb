{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubymanderna/ML_ECGR5105/blob/main/Homework_6/Homework_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esc8Lv3Z3I7l"
      },
      "source": [
        "Problem 2:\n",
        "\n",
        "a. Create a fully connected Neural Network for all 10 classes in CIFAR-10 with only one hidden layer with a size of 512. Report your training time, training loss, and evaluation accuracy. Analyze your results in your report. Make sure to submit your code by providing the GitHub URL of your course repository for this course.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghFptGroYvkD",
        "outputId": "2389e9c8-37dc-489f-dd76-2ca7b534c98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 42s 25ms/step - loss: 1.8920 - accuracy: 0.3259 - val_loss: 1.7250 - val_accuracy: 0.3857\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.7086 - accuracy: 0.3893 - val_loss: 1.6928 - val_accuracy: 0.3999\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.6384 - accuracy: 0.4181 - val_loss: 1.6035 - val_accuracy: 0.4279\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.5987 - accuracy: 0.4321 - val_loss: 1.5610 - val_accuracy: 0.4501\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5722 - accuracy: 0.4410 - val_loss: 1.5602 - val_accuracy: 0.4478\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5459 - accuracy: 0.4495 - val_loss: 1.5657 - val_accuracy: 0.4431\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.5298 - accuracy: 0.4555 - val_loss: 1.5754 - val_accuracy: 0.4415\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 1.5136 - accuracy: 0.4620 - val_loss: 1.5621 - val_accuracy: 0.4471\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.5017 - accuracy: 0.4680 - val_loss: 1.5513 - val_accuracy: 0.4578\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.4940 - accuracy: 0.4696 - val_loss: 1.5429 - val_accuracy: 0.4517\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.5429 - accuracy: 0.4517\n",
            "Training Time: 447.68 seconds\n",
            "Training Loss: 1.4940\n",
            "Validation Accuracy: 0.4517\n",
            "Test Accuracy: 0.4517\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encode labels\n",
        "\n",
        "# Build the neural network\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),  # Flatten the input images\n",
        "    layers.Dense(512, activation='relu'),  # Hidden layer with 512 neurons\n",
        "    layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F13OvGbuxtOg"
      },
      "source": [
        "b. Extend your network with two more additional hidden layers, like the example we did in the lecture (pick the sizes of hidden layers properly). Train your network. Report your training time, loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare your model size and accuracy over the baseline implementation in Problem 2.a. Do you see any over-fitting? Can you compare your model complexity against problem 2.a? Make sure to submit your code by providing the GitHub URL of your course repository for this course.(35pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_IB_KtNxvgg",
        "outputId": "56301feb-010c-49b0-88d7-0b23a2fce223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1563/1563 [==============================] - 42s 26ms/step - loss: 1.8642 - accuracy: 0.3221 - val_loss: 1.7091 - val_accuracy: 0.3857\n",
            "Epoch 2/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.6759 - accuracy: 0.3982 - val_loss: 1.5822 - val_accuracy: 0.4315\n",
            "Epoch 3/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.5906 - accuracy: 0.4300 - val_loss: 1.5986 - val_accuracy: 0.4353\n",
            "Epoch 4/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.5346 - accuracy: 0.4507 - val_loss: 1.5080 - val_accuracy: 0.4636\n",
            "Epoch 5/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.4977 - accuracy: 0.4624 - val_loss: 1.5008 - val_accuracy: 0.4664\n",
            "Epoch 6/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4644 - accuracy: 0.4756 - val_loss: 1.4897 - val_accuracy: 0.4663\n",
            "Epoch 7/300\n",
            "1563/1563 [==============================] - 50s 32ms/step - loss: 1.4321 - accuracy: 0.4879 - val_loss: 1.4671 - val_accuracy: 0.4768\n",
            "Epoch 8/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.4092 - accuracy: 0.4919 - val_loss: 1.4759 - val_accuracy: 0.4747\n",
            "Epoch 9/300\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.3843 - accuracy: 0.5021 - val_loss: 1.4605 - val_accuracy: 0.4787\n",
            "Epoch 10/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3591 - accuracy: 0.5128 - val_loss: 1.4785 - val_accuracy: 0.4775\n",
            "Epoch 11/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.3373 - accuracy: 0.5191 - val_loss: 1.4489 - val_accuracy: 0.4841\n",
            "Epoch 12/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.3182 - accuracy: 0.5256 - val_loss: 1.4338 - val_accuracy: 0.4939\n",
            "Epoch 13/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 1.3012 - accuracy: 0.5334 - val_loss: 1.5150 - val_accuracy: 0.4745\n",
            "Epoch 14/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.2828 - accuracy: 0.5370 - val_loss: 1.4313 - val_accuracy: 0.4971\n",
            "Epoch 15/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.2620 - accuracy: 0.5467 - val_loss: 1.4956 - val_accuracy: 0.4777\n",
            "Epoch 16/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2465 - accuracy: 0.5517 - val_loss: 1.4373 - val_accuracy: 0.4999\n",
            "Epoch 17/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2352 - accuracy: 0.5543 - val_loss: 1.4992 - val_accuracy: 0.4772\n",
            "Epoch 18/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 1.2176 - accuracy: 0.5609 - val_loss: 1.4753 - val_accuracy: 0.4821\n",
            "Epoch 19/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 1.1991 - accuracy: 0.5673 - val_loss: 1.4481 - val_accuracy: 0.4917\n",
            "Epoch 20/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1882 - accuracy: 0.5702 - val_loss: 1.4980 - val_accuracy: 0.4947\n",
            "Epoch 21/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1751 - accuracy: 0.5752 - val_loss: 1.5342 - val_accuracy: 0.4726\n",
            "Epoch 22/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1567 - accuracy: 0.5811 - val_loss: 1.5030 - val_accuracy: 0.4925\n",
            "Epoch 23/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 1.1503 - accuracy: 0.5857 - val_loss: 1.4859 - val_accuracy: 0.4918\n",
            "Epoch 24/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1331 - accuracy: 0.5900 - val_loss: 1.4884 - val_accuracy: 0.5018\n",
            "Epoch 25/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 1.1191 - accuracy: 0.5966 - val_loss: 1.4681 - val_accuracy: 0.4925\n",
            "Epoch 26/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1127 - accuracy: 0.5970 - val_loss: 1.5238 - val_accuracy: 0.4981\n",
            "Epoch 27/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0974 - accuracy: 0.6007 - val_loss: 1.5033 - val_accuracy: 0.5004\n",
            "Epoch 28/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0852 - accuracy: 0.6067 - val_loss: 1.5924 - val_accuracy: 0.4807\n",
            "Epoch 29/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0739 - accuracy: 0.6111 - val_loss: 1.5635 - val_accuracy: 0.4884\n",
            "Epoch 30/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0663 - accuracy: 0.6150 - val_loss: 1.5203 - val_accuracy: 0.5038\n",
            "Epoch 31/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.0484 - accuracy: 0.6203 - val_loss: 1.5524 - val_accuracy: 0.4950\n",
            "Epoch 32/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0488 - accuracy: 0.6200 - val_loss: 1.5874 - val_accuracy: 0.4921\n",
            "Epoch 33/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0369 - accuracy: 0.6242 - val_loss: 1.6167 - val_accuracy: 0.4866\n",
            "Epoch 34/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 1.0288 - accuracy: 0.6273 - val_loss: 1.5912 - val_accuracy: 0.4983\n",
            "Epoch 35/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 1.0218 - accuracy: 0.6310 - val_loss: 1.6369 - val_accuracy: 0.4867\n",
            "Epoch 36/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 1.0079 - accuracy: 0.6352 - val_loss: 1.6365 - val_accuracy: 0.4905\n",
            "Epoch 37/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.0034 - accuracy: 0.6371 - val_loss: 1.6526 - val_accuracy: 0.4901\n",
            "Epoch 38/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.9870 - accuracy: 0.6429 - val_loss: 1.7055 - val_accuracy: 0.4836\n",
            "Epoch 39/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.9853 - accuracy: 0.6426 - val_loss: 1.6672 - val_accuracy: 0.4918\n",
            "Epoch 40/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9738 - accuracy: 0.6482 - val_loss: 1.7128 - val_accuracy: 0.4909\n",
            "Epoch 41/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9641 - accuracy: 0.6500 - val_loss: 1.6781 - val_accuracy: 0.4851\n",
            "Epoch 42/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9594 - accuracy: 0.6517 - val_loss: 1.7215 - val_accuracy: 0.4901\n",
            "Epoch 43/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9502 - accuracy: 0.6558 - val_loss: 1.6867 - val_accuracy: 0.4977\n",
            "Epoch 44/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9421 - accuracy: 0.6568 - val_loss: 1.7920 - val_accuracy: 0.4686\n",
            "Epoch 45/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.9408 - accuracy: 0.6602 - val_loss: 1.8329 - val_accuracy: 0.4868\n",
            "Epoch 46/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9378 - accuracy: 0.6591 - val_loss: 1.7164 - val_accuracy: 0.4899\n",
            "Epoch 47/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9262 - accuracy: 0.6630 - val_loss: 1.7416 - val_accuracy: 0.4991\n",
            "Epoch 48/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9202 - accuracy: 0.6670 - val_loss: 1.7464 - val_accuracy: 0.4962\n",
            "Epoch 49/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9042 - accuracy: 0.6721 - val_loss: 1.7849 - val_accuracy: 0.4914\n",
            "Epoch 50/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9041 - accuracy: 0.6728 - val_loss: 1.8161 - val_accuracy: 0.4878\n",
            "Epoch 51/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.8978 - accuracy: 0.6737 - val_loss: 1.7911 - val_accuracy: 0.4985\n",
            "Epoch 52/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8882 - accuracy: 0.6771 - val_loss: 1.8444 - val_accuracy: 0.4863\n",
            "Epoch 53/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8911 - accuracy: 0.6763 - val_loss: 1.8488 - val_accuracy: 0.4884\n",
            "Epoch 54/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8771 - accuracy: 0.6807 - val_loss: 1.8532 - val_accuracy: 0.4854\n",
            "Epoch 55/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8728 - accuracy: 0.6814 - val_loss: 1.8924 - val_accuracy: 0.4895\n",
            "Epoch 56/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8748 - accuracy: 0.6833 - val_loss: 1.9986 - val_accuracy: 0.4727\n",
            "Epoch 57/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8605 - accuracy: 0.6888 - val_loss: 1.9276 - val_accuracy: 0.4813\n",
            "Epoch 58/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8650 - accuracy: 0.6877 - val_loss: 1.8694 - val_accuracy: 0.4790\n",
            "Epoch 59/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8580 - accuracy: 0.6870 - val_loss: 1.8670 - val_accuracy: 0.4889\n",
            "Epoch 60/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8423 - accuracy: 0.6918 - val_loss: 1.9038 - val_accuracy: 0.4916\n",
            "Epoch 61/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8473 - accuracy: 0.6923 - val_loss: 2.0178 - val_accuracy: 0.4838\n",
            "Epoch 62/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.8382 - accuracy: 0.6970 - val_loss: 2.0385 - val_accuracy: 0.4830\n",
            "Epoch 63/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8274 - accuracy: 0.6999 - val_loss: 2.0043 - val_accuracy: 0.4876\n",
            "Epoch 64/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8366 - accuracy: 0.6969 - val_loss: 1.9843 - val_accuracy: 0.4847\n",
            "Epoch 65/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8236 - accuracy: 0.7007 - val_loss: 1.9952 - val_accuracy: 0.4848\n",
            "Epoch 66/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8220 - accuracy: 0.6995 - val_loss: 2.0563 - val_accuracy: 0.4802\n",
            "Epoch 67/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.8246 - accuracy: 0.7008 - val_loss: 2.0975 - val_accuracy: 0.4841\n",
            "Epoch 68/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8097 - accuracy: 0.7061 - val_loss: 2.0494 - val_accuracy: 0.4852\n",
            "Epoch 69/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8062 - accuracy: 0.7083 - val_loss: 2.1225 - val_accuracy: 0.4784\n",
            "Epoch 70/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7999 - accuracy: 0.7099 - val_loss: 2.1925 - val_accuracy: 0.4764\n",
            "Epoch 71/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8037 - accuracy: 0.7089 - val_loss: 2.1183 - val_accuracy: 0.4799\n",
            "Epoch 72/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7895 - accuracy: 0.7130 - val_loss: 2.0875 - val_accuracy: 0.4866\n",
            "Epoch 73/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7890 - accuracy: 0.7148 - val_loss: 2.1113 - val_accuracy: 0.4795\n",
            "Epoch 74/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7832 - accuracy: 0.7152 - val_loss: 2.1620 - val_accuracy: 0.4827\n",
            "Epoch 75/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7793 - accuracy: 0.7182 - val_loss: 2.1911 - val_accuracy: 0.4813\n",
            "Epoch 76/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7743 - accuracy: 0.7209 - val_loss: 2.3389 - val_accuracy: 0.4819\n",
            "Epoch 77/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7711 - accuracy: 0.7217 - val_loss: 2.1728 - val_accuracy: 0.4790\n",
            "Epoch 78/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7681 - accuracy: 0.7212 - val_loss: 2.3344 - val_accuracy: 0.4761\n",
            "Epoch 79/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7573 - accuracy: 0.7240 - val_loss: 2.1946 - val_accuracy: 0.4835\n",
            "Epoch 80/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7683 - accuracy: 0.7200 - val_loss: 2.1578 - val_accuracy: 0.4821\n",
            "Epoch 81/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7650 - accuracy: 0.7217 - val_loss: 2.3528 - val_accuracy: 0.4779\n",
            "Epoch 82/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7534 - accuracy: 0.7264 - val_loss: 2.2678 - val_accuracy: 0.4836\n",
            "Epoch 83/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7414 - accuracy: 0.7288 - val_loss: 2.2807 - val_accuracy: 0.4724\n",
            "Epoch 84/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7501 - accuracy: 0.7277 - val_loss: 2.3409 - val_accuracy: 0.4729\n",
            "Epoch 85/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7479 - accuracy: 0.7295 - val_loss: 2.3307 - val_accuracy: 0.4837\n",
            "Epoch 86/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.7371 - accuracy: 0.7336 - val_loss: 2.2709 - val_accuracy: 0.4815\n",
            "Epoch 87/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7431 - accuracy: 0.7296 - val_loss: 2.2975 - val_accuracy: 0.4824\n",
            "Epoch 88/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7430 - accuracy: 0.7301 - val_loss: 2.3927 - val_accuracy: 0.4805\n",
            "Epoch 89/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7301 - accuracy: 0.7359 - val_loss: 2.4863 - val_accuracy: 0.4717\n",
            "Epoch 90/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7341 - accuracy: 0.7336 - val_loss: 2.2821 - val_accuracy: 0.4802\n",
            "Epoch 91/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7283 - accuracy: 0.7360 - val_loss: 2.4875 - val_accuracy: 0.4733\n",
            "Epoch 92/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7295 - accuracy: 0.7354 - val_loss: 2.3108 - val_accuracy: 0.4726\n",
            "Epoch 93/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7218 - accuracy: 0.7395 - val_loss: 2.3521 - val_accuracy: 0.4783\n",
            "Epoch 94/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7157 - accuracy: 0.7405 - val_loss: 2.4793 - val_accuracy: 0.4696\n",
            "Epoch 95/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.7227 - accuracy: 0.7383 - val_loss: 2.4641 - val_accuracy: 0.4708\n",
            "Epoch 96/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7122 - accuracy: 0.7419 - val_loss: 2.4195 - val_accuracy: 0.4844\n",
            "Epoch 97/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7049 - accuracy: 0.7430 - val_loss: 2.5223 - val_accuracy: 0.4764\n",
            "Epoch 98/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7143 - accuracy: 0.7411 - val_loss: 2.4308 - val_accuracy: 0.4744\n",
            "Epoch 99/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6992 - accuracy: 0.7455 - val_loss: 2.6401 - val_accuracy: 0.4756\n",
            "Epoch 100/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6956 - accuracy: 0.7472 - val_loss: 2.4405 - val_accuracy: 0.4700\n",
            "Epoch 101/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7062 - accuracy: 0.7442 - val_loss: 2.5335 - val_accuracy: 0.4755\n",
            "Epoch 102/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6957 - accuracy: 0.7469 - val_loss: 2.6467 - val_accuracy: 0.4717\n",
            "Epoch 103/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6921 - accuracy: 0.7477 - val_loss: 2.5251 - val_accuracy: 0.4845\n",
            "Epoch 104/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6840 - accuracy: 0.7520 - val_loss: 2.5750 - val_accuracy: 0.4682\n",
            "Epoch 105/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6907 - accuracy: 0.7483 - val_loss: 2.5570 - val_accuracy: 0.4791\n",
            "Epoch 106/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6799 - accuracy: 0.7533 - val_loss: 2.5050 - val_accuracy: 0.4720\n",
            "Epoch 107/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6841 - accuracy: 0.7517 - val_loss: 2.6814 - val_accuracy: 0.4689\n",
            "Epoch 108/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6796 - accuracy: 0.7543 - val_loss: 2.6236 - val_accuracy: 0.4726\n",
            "Epoch 109/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6763 - accuracy: 0.7551 - val_loss: 2.7244 - val_accuracy: 0.4745\n",
            "Epoch 110/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6852 - accuracy: 0.7529 - val_loss: 2.7515 - val_accuracy: 0.4719\n",
            "Epoch 111/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6612 - accuracy: 0.7600 - val_loss: 2.6656 - val_accuracy: 0.4687\n",
            "Epoch 112/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6776 - accuracy: 0.7538 - val_loss: 2.7273 - val_accuracy: 0.4732\n",
            "Epoch 113/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6640 - accuracy: 0.7593 - val_loss: 2.7971 - val_accuracy: 0.4697\n",
            "Epoch 114/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6726 - accuracy: 0.7567 - val_loss: 2.7438 - val_accuracy: 0.4679\n",
            "Epoch 115/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.6717 - accuracy: 0.7555 - val_loss: 2.6341 - val_accuracy: 0.4723\n",
            "Epoch 116/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6584 - accuracy: 0.7618 - val_loss: 2.7268 - val_accuracy: 0.4786\n",
            "Epoch 117/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6654 - accuracy: 0.7610 - val_loss: 2.6947 - val_accuracy: 0.4754\n",
            "Epoch 118/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6652 - accuracy: 0.7591 - val_loss: 2.7209 - val_accuracy: 0.4730\n",
            "Epoch 119/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6557 - accuracy: 0.7639 - val_loss: 2.8485 - val_accuracy: 0.4623\n",
            "Epoch 120/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6534 - accuracy: 0.7648 - val_loss: 3.1170 - val_accuracy: 0.4694\n",
            "Epoch 121/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6456 - accuracy: 0.7661 - val_loss: 2.8204 - val_accuracy: 0.4677\n",
            "Epoch 122/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6690 - accuracy: 0.7571 - val_loss: 2.8370 - val_accuracy: 0.4673\n",
            "Epoch 123/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6405 - accuracy: 0.7680 - val_loss: 2.8044 - val_accuracy: 0.4803\n",
            "Epoch 124/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6443 - accuracy: 0.7674 - val_loss: 2.7501 - val_accuracy: 0.4751\n",
            "Epoch 125/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6419 - accuracy: 0.7687 - val_loss: 2.9090 - val_accuracy: 0.4652\n",
            "Epoch 126/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6463 - accuracy: 0.7659 - val_loss: 2.8716 - val_accuracy: 0.4768\n",
            "Epoch 127/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6398 - accuracy: 0.7668 - val_loss: 3.1863 - val_accuracy: 0.4694\n",
            "Epoch 128/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6421 - accuracy: 0.7684 - val_loss: 2.9391 - val_accuracy: 0.4752\n",
            "Epoch 129/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6447 - accuracy: 0.7688 - val_loss: 2.9726 - val_accuracy: 0.4743\n",
            "Epoch 130/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.6293 - accuracy: 0.7729 - val_loss: 2.9258 - val_accuracy: 0.4671\n",
            "Epoch 131/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.6399 - accuracy: 0.7712 - val_loss: 3.0457 - val_accuracy: 0.4740\n",
            "Epoch 132/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6306 - accuracy: 0.7714 - val_loss: 2.8089 - val_accuracy: 0.4675\n",
            "Epoch 133/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6288 - accuracy: 0.7731 - val_loss: 2.8844 - val_accuracy: 0.4783\n",
            "Epoch 134/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6240 - accuracy: 0.7758 - val_loss: 3.0233 - val_accuracy: 0.4738\n",
            "Epoch 135/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6285 - accuracy: 0.7710 - val_loss: 2.9935 - val_accuracy: 0.4716\n",
            "Epoch 136/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6290 - accuracy: 0.7725 - val_loss: 2.9444 - val_accuracy: 0.4744\n",
            "Epoch 137/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6238 - accuracy: 0.7740 - val_loss: 3.1982 - val_accuracy: 0.4585\n",
            "Epoch 138/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6215 - accuracy: 0.7753 - val_loss: 3.0478 - val_accuracy: 0.4693\n",
            "Epoch 139/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6322 - accuracy: 0.7751 - val_loss: 3.1275 - val_accuracy: 0.4688\n",
            "Epoch 140/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6107 - accuracy: 0.7794 - val_loss: 3.0710 - val_accuracy: 0.4741\n",
            "Epoch 141/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6117 - accuracy: 0.7782 - val_loss: 3.0466 - val_accuracy: 0.4730\n",
            "Epoch 142/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6113 - accuracy: 0.7804 - val_loss: 2.9285 - val_accuracy: 0.4637\n",
            "Epoch 143/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6154 - accuracy: 0.7774 - val_loss: 3.0448 - val_accuracy: 0.4670\n",
            "Epoch 144/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6123 - accuracy: 0.7797 - val_loss: 3.2123 - val_accuracy: 0.4699\n",
            "Epoch 145/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6079 - accuracy: 0.7813 - val_loss: 3.1713 - val_accuracy: 0.4649\n",
            "Epoch 146/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6021 - accuracy: 0.7824 - val_loss: 3.1666 - val_accuracy: 0.4755\n",
            "Epoch 147/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6157 - accuracy: 0.7789 - val_loss: 3.1666 - val_accuracy: 0.4723\n",
            "Epoch 148/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6057 - accuracy: 0.7817 - val_loss: 3.2062 - val_accuracy: 0.4673\n",
            "Epoch 149/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5981 - accuracy: 0.7845 - val_loss: 3.2491 - val_accuracy: 0.4743\n",
            "Epoch 150/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6125 - accuracy: 0.7792 - val_loss: 3.1868 - val_accuracy: 0.4676\n",
            "Epoch 151/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5972 - accuracy: 0.7847 - val_loss: 3.1326 - val_accuracy: 0.4657\n",
            "Epoch 152/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6016 - accuracy: 0.7814 - val_loss: 3.3022 - val_accuracy: 0.4726\n",
            "Epoch 153/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5983 - accuracy: 0.7837 - val_loss: 2.9801 - val_accuracy: 0.4629\n",
            "Epoch 154/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5925 - accuracy: 0.7861 - val_loss: 3.1344 - val_accuracy: 0.4755\n",
            "Epoch 155/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5803 - accuracy: 0.7912 - val_loss: 3.0749 - val_accuracy: 0.4639\n",
            "Epoch 156/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5981 - accuracy: 0.7848 - val_loss: 3.2683 - val_accuracy: 0.4660\n",
            "Epoch 157/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5859 - accuracy: 0.7884 - val_loss: 3.2969 - val_accuracy: 0.4699\n",
            "Epoch 158/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5893 - accuracy: 0.7862 - val_loss: 3.3388 - val_accuracy: 0.4687\n",
            "Epoch 159/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5912 - accuracy: 0.7843 - val_loss: 3.3047 - val_accuracy: 0.4691\n",
            "Epoch 160/300\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.5819 - accuracy: 0.7921 - val_loss: 3.3124 - val_accuracy: 0.4564\n",
            "Epoch 161/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5910 - accuracy: 0.7902 - val_loss: 3.2275 - val_accuracy: 0.4651\n",
            "Epoch 162/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5912 - accuracy: 0.7863 - val_loss: 3.4388 - val_accuracy: 0.4643\n",
            "Epoch 163/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5931 - accuracy: 0.7873 - val_loss: 3.3652 - val_accuracy: 0.4686\n",
            "Epoch 164/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5834 - accuracy: 0.7918 - val_loss: 3.4788 - val_accuracy: 0.4637\n",
            "Epoch 165/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5897 - accuracy: 0.7881 - val_loss: 3.2305 - val_accuracy: 0.4672\n",
            "Epoch 166/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5810 - accuracy: 0.7930 - val_loss: 3.4856 - val_accuracy: 0.4629\n",
            "Epoch 167/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5749 - accuracy: 0.7908 - val_loss: 3.3815 - val_accuracy: 0.4629\n",
            "Epoch 168/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5818 - accuracy: 0.7889 - val_loss: 3.5633 - val_accuracy: 0.4657\n",
            "Epoch 169/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5657 - accuracy: 0.7954 - val_loss: 3.3425 - val_accuracy: 0.4643\n",
            "Epoch 170/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5758 - accuracy: 0.7965 - val_loss: 3.6725 - val_accuracy: 0.4629\n",
            "Epoch 171/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5756 - accuracy: 0.7930 - val_loss: 3.5694 - val_accuracy: 0.4629\n",
            "Epoch 172/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5676 - accuracy: 0.7944 - val_loss: 3.5849 - val_accuracy: 0.4642\n",
            "Epoch 173/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5753 - accuracy: 0.7926 - val_loss: 3.4792 - val_accuracy: 0.4588\n",
            "Epoch 174/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5580 - accuracy: 0.7987 - val_loss: 3.4979 - val_accuracy: 0.4644\n",
            "Epoch 175/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5744 - accuracy: 0.7945 - val_loss: 3.4611 - val_accuracy: 0.4699\n",
            "Epoch 176/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5752 - accuracy: 0.7933 - val_loss: 3.6581 - val_accuracy: 0.4672\n",
            "Epoch 177/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5582 - accuracy: 0.7993 - val_loss: 3.5538 - val_accuracy: 0.4622\n",
            "Epoch 178/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5815 - accuracy: 0.7929 - val_loss: 3.5191 - val_accuracy: 0.4681\n",
            "Epoch 179/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5601 - accuracy: 0.7987 - val_loss: 3.4325 - val_accuracy: 0.4576\n",
            "Epoch 180/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5640 - accuracy: 0.7977 - val_loss: 3.7974 - val_accuracy: 0.4590\n",
            "Epoch 181/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5666 - accuracy: 0.7960 - val_loss: 3.6987 - val_accuracy: 0.4615\n",
            "Epoch 182/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5488 - accuracy: 0.8036 - val_loss: 3.8996 - val_accuracy: 0.4636\n",
            "Epoch 183/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5657 - accuracy: 0.7971 - val_loss: 3.5760 - val_accuracy: 0.4639\n",
            "Epoch 184/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5539 - accuracy: 0.8010 - val_loss: 3.7994 - val_accuracy: 0.4632\n",
            "Epoch 185/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5631 - accuracy: 0.7983 - val_loss: 3.4901 - val_accuracy: 0.4620\n",
            "Epoch 186/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5606 - accuracy: 0.8003 - val_loss: 3.5881 - val_accuracy: 0.4639\n",
            "Epoch 187/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5596 - accuracy: 0.8010 - val_loss: 3.6500 - val_accuracy: 0.4655\n",
            "Epoch 188/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5515 - accuracy: 0.8012 - val_loss: 3.7213 - val_accuracy: 0.4571\n",
            "Epoch 189/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5642 - accuracy: 0.7978 - val_loss: 3.7018 - val_accuracy: 0.4631\n",
            "Epoch 190/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5444 - accuracy: 0.8048 - val_loss: 3.6634 - val_accuracy: 0.4611\n",
            "Epoch 191/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5715 - accuracy: 0.7957 - val_loss: 3.5947 - val_accuracy: 0.4615\n",
            "Epoch 192/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5356 - accuracy: 0.8058 - val_loss: 3.8734 - val_accuracy: 0.4574\n",
            "Epoch 193/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5378 - accuracy: 0.8053 - val_loss: 3.9838 - val_accuracy: 0.4641\n",
            "Epoch 194/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5665 - accuracy: 0.7997 - val_loss: 3.7251 - val_accuracy: 0.4629\n",
            "Epoch 195/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5270 - accuracy: 0.8119 - val_loss: 3.9771 - val_accuracy: 0.4546\n",
            "Epoch 196/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5444 - accuracy: 0.8055 - val_loss: 3.9069 - val_accuracy: 0.4590\n",
            "Epoch 197/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5461 - accuracy: 0.8057 - val_loss: 3.8932 - val_accuracy: 0.4693\n",
            "Epoch 198/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5477 - accuracy: 0.8031 - val_loss: 3.8020 - val_accuracy: 0.4615\n",
            "Epoch 199/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5368 - accuracy: 0.8057 - val_loss: 3.8703 - val_accuracy: 0.4620\n",
            "Epoch 200/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5468 - accuracy: 0.8066 - val_loss: 3.8578 - val_accuracy: 0.4668\n",
            "Epoch 201/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5372 - accuracy: 0.8072 - val_loss: 3.8005 - val_accuracy: 0.4590\n",
            "Epoch 202/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5591 - accuracy: 0.8016 - val_loss: 3.9609 - val_accuracy: 0.4619\n",
            "Epoch 203/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5369 - accuracy: 0.8077 - val_loss: 4.0999 - val_accuracy: 0.4619\n",
            "Epoch 204/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5409 - accuracy: 0.8082 - val_loss: 3.8747 - val_accuracy: 0.4681\n",
            "Epoch 205/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5375 - accuracy: 0.8074 - val_loss: 3.9051 - val_accuracy: 0.4617\n",
            "Epoch 206/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5400 - accuracy: 0.8063 - val_loss: 3.9069 - val_accuracy: 0.4586\n",
            "Epoch 207/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5303 - accuracy: 0.8073 - val_loss: 3.7956 - val_accuracy: 0.4674\n",
            "Epoch 208/300\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.5265 - accuracy: 0.8084 - val_loss: 3.9488 - val_accuracy: 0.4625\n",
            "Epoch 209/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5348 - accuracy: 0.8078 - val_loss: 4.1944 - val_accuracy: 0.4641\n",
            "Epoch 210/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5490 - accuracy: 0.8058 - val_loss: 4.0976 - val_accuracy: 0.4610\n",
            "Epoch 211/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5176 - accuracy: 0.8142 - val_loss: 4.0848 - val_accuracy: 0.4583\n",
            "Epoch 212/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5284 - accuracy: 0.8113 - val_loss: 4.2294 - val_accuracy: 0.4615\n",
            "Epoch 213/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5408 - accuracy: 0.8072 - val_loss: 3.8473 - val_accuracy: 0.4584\n",
            "Epoch 214/300\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5116 - accuracy: 0.8169 - val_loss: 4.0250 - val_accuracy: 0.4626\n",
            "Epoch 215/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5345 - accuracy: 0.8096 - val_loss: 3.9815 - val_accuracy: 0.4614\n",
            "Epoch 216/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5366 - accuracy: 0.8073 - val_loss: 4.0269 - val_accuracy: 0.4649\n",
            "Epoch 217/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5226 - accuracy: 0.8126 - val_loss: 4.0268 - val_accuracy: 0.4615\n",
            "Epoch 218/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5243 - accuracy: 0.8131 - val_loss: 4.1199 - val_accuracy: 0.4613\n",
            "Epoch 219/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5208 - accuracy: 0.8128 - val_loss: 3.8591 - val_accuracy: 0.4615\n",
            "Epoch 220/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.5359 - accuracy: 0.8075 - val_loss: 3.9325 - val_accuracy: 0.4643\n",
            "Epoch 221/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.5157 - accuracy: 0.8151 - val_loss: 4.2504 - val_accuracy: 0.4640\n",
            "Epoch 222/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5213 - accuracy: 0.8147 - val_loss: 4.1345 - val_accuracy: 0.4612\n",
            "Epoch 223/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5287 - accuracy: 0.8108 - val_loss: 4.3241 - val_accuracy: 0.4549\n",
            "Epoch 224/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5198 - accuracy: 0.8152 - val_loss: 4.2112 - val_accuracy: 0.4529\n",
            "Epoch 225/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5105 - accuracy: 0.8167 - val_loss: 4.0310 - val_accuracy: 0.4592\n",
            "Epoch 226/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5227 - accuracy: 0.8122 - val_loss: 4.1965 - val_accuracy: 0.4616\n",
            "Epoch 227/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5292 - accuracy: 0.8134 - val_loss: 4.0973 - val_accuracy: 0.4574\n",
            "Epoch 228/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5249 - accuracy: 0.8130 - val_loss: 4.1223 - val_accuracy: 0.4555\n",
            "Epoch 229/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5010 - accuracy: 0.8197 - val_loss: 4.1713 - val_accuracy: 0.4623\n",
            "Epoch 230/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5251 - accuracy: 0.8164 - val_loss: 4.1601 - val_accuracy: 0.4605\n",
            "Epoch 231/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5009 - accuracy: 0.8214 - val_loss: 4.4911 - val_accuracy: 0.4635\n",
            "Epoch 232/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5134 - accuracy: 0.8163 - val_loss: 4.3277 - val_accuracy: 0.4559\n",
            "Epoch 233/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5101 - accuracy: 0.8183 - val_loss: 4.2630 - val_accuracy: 0.4627\n",
            "Epoch 234/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5287 - accuracy: 0.8141 - val_loss: 4.2925 - val_accuracy: 0.4617\n",
            "Epoch 235/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5101 - accuracy: 0.8193 - val_loss: 3.9977 - val_accuracy: 0.4593\n",
            "Epoch 236/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.5082 - accuracy: 0.8189 - val_loss: 4.4244 - val_accuracy: 0.4557\n",
            "Epoch 237/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5160 - accuracy: 0.8176 - val_loss: 4.3941 - val_accuracy: 0.4650\n",
            "Epoch 238/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5148 - accuracy: 0.8182 - val_loss: 4.3274 - val_accuracy: 0.4584\n",
            "Epoch 239/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5170 - accuracy: 0.8158 - val_loss: 4.0988 - val_accuracy: 0.4570\n",
            "Epoch 240/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5087 - accuracy: 0.8183 - val_loss: 4.3238 - val_accuracy: 0.4588\n",
            "Epoch 241/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5189 - accuracy: 0.8159 - val_loss: 4.2855 - val_accuracy: 0.4581\n",
            "Epoch 242/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5183 - accuracy: 0.8175 - val_loss: 4.3715 - val_accuracy: 0.4552\n",
            "Epoch 243/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5182 - accuracy: 0.8165 - val_loss: 4.2828 - val_accuracy: 0.4565\n",
            "Epoch 244/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5016 - accuracy: 0.8202 - val_loss: 4.2146 - val_accuracy: 0.4609\n",
            "Epoch 245/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5048 - accuracy: 0.8224 - val_loss: 4.4711 - val_accuracy: 0.4583\n",
            "Epoch 246/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5001 - accuracy: 0.8207 - val_loss: 4.5162 - val_accuracy: 0.4565\n",
            "Epoch 247/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5040 - accuracy: 0.8205 - val_loss: 4.4266 - val_accuracy: 0.4597\n",
            "Epoch 248/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5017 - accuracy: 0.8204 - val_loss: 4.5916 - val_accuracy: 0.4599\n",
            "Epoch 249/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4982 - accuracy: 0.8244 - val_loss: 4.4063 - val_accuracy: 0.4563\n",
            "Epoch 250/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5093 - accuracy: 0.8198 - val_loss: 4.3496 - val_accuracy: 0.4566\n",
            "Epoch 251/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5075 - accuracy: 0.8213 - val_loss: 4.4891 - val_accuracy: 0.4616\n",
            "Epoch 252/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5050 - accuracy: 0.8211 - val_loss: 4.2652 - val_accuracy: 0.4621\n",
            "Epoch 253/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4900 - accuracy: 0.8260 - val_loss: 4.3305 - val_accuracy: 0.4586\n",
            "Epoch 254/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5042 - accuracy: 0.8217 - val_loss: 4.4463 - val_accuracy: 0.4531\n",
            "Epoch 255/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5138 - accuracy: 0.8200 - val_loss: 4.3115 - val_accuracy: 0.4604\n",
            "Epoch 256/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5123 - accuracy: 0.8212 - val_loss: 4.4662 - val_accuracy: 0.4598\n",
            "Epoch 257/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4885 - accuracy: 0.8249 - val_loss: 4.2547 - val_accuracy: 0.4589\n",
            "Epoch 258/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4926 - accuracy: 0.8250 - val_loss: 4.6661 - val_accuracy: 0.4620\n",
            "Epoch 259/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4892 - accuracy: 0.8278 - val_loss: 4.6198 - val_accuracy: 0.4634\n",
            "Epoch 260/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5003 - accuracy: 0.8223 - val_loss: 4.8234 - val_accuracy: 0.4583\n",
            "Epoch 261/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4968 - accuracy: 0.8245 - val_loss: 5.1058 - val_accuracy: 0.4576\n",
            "Epoch 262/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5057 - accuracy: 0.8214 - val_loss: 4.4031 - val_accuracy: 0.4609\n",
            "Epoch 263/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4784 - accuracy: 0.8283 - val_loss: 4.7388 - val_accuracy: 0.4624\n",
            "Epoch 264/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5103 - accuracy: 0.8214 - val_loss: 4.5877 - val_accuracy: 0.4634\n",
            "Epoch 265/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4740 - accuracy: 0.8319 - val_loss: 4.5115 - val_accuracy: 0.4612\n",
            "Epoch 266/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5017 - accuracy: 0.8237 - val_loss: 4.9547 - val_accuracy: 0.4502\n",
            "Epoch 267/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5118 - accuracy: 0.8215 - val_loss: 4.5985 - val_accuracy: 0.4485\n",
            "Epoch 268/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4928 - accuracy: 0.8262 - val_loss: 4.6873 - val_accuracy: 0.4520\n",
            "Epoch 269/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5019 - accuracy: 0.8240 - val_loss: 4.6705 - val_accuracy: 0.4653\n",
            "Epoch 270/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4842 - accuracy: 0.8294 - val_loss: 4.4689 - val_accuracy: 0.4565\n",
            "Epoch 271/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5094 - accuracy: 0.8222 - val_loss: 4.9270 - val_accuracy: 0.4582\n",
            "Epoch 272/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4894 - accuracy: 0.8281 - val_loss: 4.5910 - val_accuracy: 0.4501\n",
            "Epoch 273/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4971 - accuracy: 0.8252 - val_loss: 4.6364 - val_accuracy: 0.4560\n",
            "Epoch 274/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4820 - accuracy: 0.8290 - val_loss: 4.5898 - val_accuracy: 0.4582\n",
            "Epoch 275/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4895 - accuracy: 0.8276 - val_loss: 5.0417 - val_accuracy: 0.4484\n",
            "Epoch 276/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.5008 - accuracy: 0.8232 - val_loss: 4.8111 - val_accuracy: 0.4630\n",
            "Epoch 277/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4782 - accuracy: 0.8297 - val_loss: 4.7891 - val_accuracy: 0.4545\n",
            "Epoch 278/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.5002 - accuracy: 0.8241 - val_loss: 4.7384 - val_accuracy: 0.4578\n",
            "Epoch 279/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.4904 - accuracy: 0.8260 - val_loss: 4.9567 - val_accuracy: 0.4538\n",
            "Epoch 280/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4818 - accuracy: 0.8307 - val_loss: 4.5543 - val_accuracy: 0.4451\n",
            "Epoch 281/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4912 - accuracy: 0.8263 - val_loss: 4.7301 - val_accuracy: 0.4619\n",
            "Epoch 282/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4809 - accuracy: 0.8280 - val_loss: 4.9672 - val_accuracy: 0.4586\n",
            "Epoch 283/300\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.5033 - accuracy: 0.8231 - val_loss: 4.6695 - val_accuracy: 0.4540\n",
            "Epoch 284/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4607 - accuracy: 0.8348 - val_loss: 4.8618 - val_accuracy: 0.4574\n",
            "Epoch 285/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4832 - accuracy: 0.8300 - val_loss: 4.8919 - val_accuracy: 0.4604\n",
            "Epoch 286/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4997 - accuracy: 0.8248 - val_loss: 4.7315 - val_accuracy: 0.4571\n",
            "Epoch 287/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4640 - accuracy: 0.8359 - val_loss: 5.1410 - val_accuracy: 0.4515\n",
            "Epoch 288/300\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 0.4861 - accuracy: 0.8315 - val_loss: 5.0443 - val_accuracy: 0.4611\n",
            "Epoch 289/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4829 - accuracy: 0.8293 - val_loss: 4.8146 - val_accuracy: 0.4581\n",
            "Epoch 290/300\n",
            "1563/1563 [==============================] - 44s 28ms/step - loss: 0.4699 - accuracy: 0.8339 - val_loss: 4.9249 - val_accuracy: 0.4588\n",
            "Epoch 291/300\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.4753 - accuracy: 0.8326 - val_loss: 4.9108 - val_accuracy: 0.4573\n",
            "Epoch 292/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5063 - accuracy: 0.8245 - val_loss: 4.8076 - val_accuracy: 0.4552\n",
            "Epoch 293/300\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.4849 - accuracy: 0.8304 - val_loss: 4.7652 - val_accuracy: 0.4583\n",
            "Epoch 294/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4667 - accuracy: 0.8324 - val_loss: 4.8294 - val_accuracy: 0.4626\n",
            "Epoch 295/300\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.4898 - accuracy: 0.8303 - val_loss: 4.9059 - val_accuracy: 0.4578\n",
            "Epoch 296/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4753 - accuracy: 0.8333 - val_loss: 4.9958 - val_accuracy: 0.4600\n",
            "Epoch 297/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4701 - accuracy: 0.8342 - val_loss: 4.9334 - val_accuracy: 0.4543\n",
            "Epoch 298/300\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.4769 - accuracy: 0.8331 - val_loss: 4.8548 - val_accuracy: 0.4554\n",
            "Epoch 299/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4791 - accuracy: 0.8314 - val_loss: 4.8264 - val_accuracy: 0.4553\n",
            "Epoch 300/300\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.4828 - accuracy: 0.8276 - val_loss: 5.1423 - val_accuracy: 0.4482\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 5.1423 - accuracy: 0.4482\n",
            "\n",
            "Extended Model:\n",
            "Training Time: 12204.89 seconds\n",
            "Training Loss: 0.4828\n",
            "Validation Accuracy: 0.4482\n",
            "Test Accuracy: 0.4482\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encode labels\n",
        "\n",
        "# Build the extended neural network with two additional hidden layers\n",
        "model_extended = models.Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),  # Flatten the input images\n",
        "    layers.Dense(512, activation='relu'),  # Hidden layer 1 with 512 neurons\n",
        "    layers.Dense(256, activation='relu'),  # Hidden layer 2 with 256 neurons\n",
        "    layers.Dense(128, activation='relu'),  # Hidden layer 3 with 128 neurons\n",
        "    layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
        "])\n",
        "\n",
        "# Compile the extended model\n",
        "model_extended.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the extended model for 300 epochs\n",
        "start_time_extended = time.time()\n",
        "history_extended = model_extended.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))\n",
        "training_time_extended = time.time() - start_time_extended\n",
        "\n",
        "# Evaluate the extended model on the test set\n",
        "test_loss_extended, test_accuracy_extended = model_extended.evaluate(x_test, y_test)\n",
        "\n",
        "# Print results for the extended model\n",
        "print(f\"\\nExtended Model:\")\n",
        "print(f\"Training Time: {training_time_extended:.2f} seconds\")\n",
        "print(f\"Training Loss: {history_extended.history['loss'][-1]:.4f}\")\n",
        "print(f\"Validation Accuracy: {history_extended.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy_extended:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MRFuEOVZlnc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4YsZmgO4iWH/LJTssj+vP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}