{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Tu51cebkGCqMpxwQGwbrRpcSpDagfpme",
      "authorship_tag": "ABX9TyP+NDthubiLAivZemB8qqu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubymanderna/ML_ECGR5105/blob/main/Homework_3_ML/Homework_3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3 (20pts):\n",
        "\n",
        "Use the cancer dataset to build a naive Bayesian model to classify the type of cancer (Malignant vs. benign). Use 80% and 20% split between training and evaluation (test). Report your classification accuracy, precision, recall, and F1 score. Explain and elaborate on your results. Can you compare your results against the logistic regression classifier you did in Problem 2."
      ],
      "metadata": {
        "id": "ntjUEVXJ5XJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cJ6XvMyU4xN7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ML_ECGR5105/cancer.csv\")\n",
        "print(df.columns)\n",
        "df = df.drop(columns=['Unnamed: 32'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6TS8Xhs5uyV",
        "outputId": "9600f1b8-bbb4-4b26-b8b1-69ed0a4234e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the features (min-max scaling)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='M')  # Assuming Malignant is the positive class\n",
        "recall = recall_score(y_test, y_pred, pos_label='M')\n",
        "f1 = f1_score(y_test, y_pred, pos_label='M')\n",
        "\n",
        "# Print metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY1S1goe5_dj",
        "outputId": "44dab04b-db20-4b7f-80f2-8369b4d8ed76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.975609756097561\n",
            "Recall: 0.9302325581395349\n",
            "F1 Score: 0.9523809523809524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final result from problem 2**\n",
        "\n",
        "After adding weight penalty\n",
        "\n",
        "Final Accuracy: 0.9736842105263158\n",
        "\n",
        "Final Precision: 1.0\n",
        "\n",
        "Final Recall: 0.9302325581395349\n",
        "\n",
        "Final F1 Score: 0.963855421686747\n",
        "\n",
        "Confusion Matrix:\n",
        "[[71 0]\n",
        "\n",
        "[ 3 40]]\n",
        "\n",
        "The addition of a penalty term helped to regularize our model and prevent overfitting up to some extent (very slightly but yes) confusion matrix- in Normalize method we have 0 false positive cases, However, we have False negative increase by 1 but on the other hand true negative decreased by 1, our desired goal for cancer data should be to decrease the number of False negative results, Based on confusion matrix better model was without adding penalties(this is based on cancer scenario assumptions).\n",
        "\n",
        "\n",
        "**final result from problem 3**\n",
        "\n",
        "Accuracy: 0.9649122807017544\n",
        "\n",
        "Precision: 0.975609756097561\n",
        "\n",
        "Recall: 0.9302325581395349\n",
        "\n",
        "F1 Score: 0.9523809523809524\n",
        "\n",
        "compare - in our case logistic regression classifier is prformin better for all the metrics.However,if model is overfitting then using naive bias would be good choice here."
      ],
      "metadata": {
        "id": "MvtF_d7F_Nvz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8gqvhYn6Xik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}