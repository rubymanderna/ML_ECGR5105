{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubymanderna/ML_ECGR5105/blob/main/Assignment_7/Assignment_7_2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXXCeAzQjQd1"
      },
      "source": [
        "Problem 2 (50pts)\n",
        "a. Build a ResNet-based Convolutional Neural Network, like what we built in lectures (with skip connections), to classify the images across all 10 classes in CIFAR 10. For this problem, let's use 10 blocks for ResNet and call it ResNet-10. Use similar dimensions and channels as we need in lectures.\n",
        "Train your network for 300 epochs. Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against problem 1.b on training time, achieved accuracy, and model size.\n",
        "Make sure to submit your code by providing the GitHub URL of your course repository for this course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljw29pkFjPn-"
      },
      "source": [
        ". Perform three additional training and evaluations for your ResNet-10 to assess the impacts of regularization on your ResNet-10.\n",
        "* ﻿﻿Weight Decay with lambda of 0.001\n",
        "* ﻿﻿Dropout with p=0.3\n",
        "* ﻿﻿Batch Normalization\n",
        "Report and compare your training time, training loss, and evaluation accuracy after 300 epochs across these three different pieces of training.\n",
        "Analyze your results in your report and compare them against problem 1. On training time, you achieved accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the Residual Block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.downsample(identity)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet-10 architecture\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(16, 16, num_blocks=2, stride=1)\n",
        "        self.layer2 = self.make_layer(16, 32, num_blocks=2, stride=2)\n",
        "        self.layer3 = self.make_layer(32, 64, num_blocks=2, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "# Function to train and evaluate the model with early stopping\n",
        "def train_and_evaluate(model, criterion, optimizer, num_epochs=3, regularization_name=\"None\", early_stop_threshold=5):\n",
        "    print(f\"Training ResNet-10 with {regularization_name} regularization:\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        print(f\"Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == early_stop_threshold:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} as validation loss did not improve for {early_stop_threshold} epochs.\")\n",
        "            break\n",
        "\n",
        "    # Evaluation (unchanged)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Training Time: {num_epochs} epochs, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Initialize the ResNet-10 model, loss function, and optimizer for each scenario\n",
        "model_no_regularization = ResNet10(num_classes=10).to(device)\n",
        "model_weight_decay = ResNet10(num_classes=10).to(device)\n",
        "model_dropout = ResNet10(num_classes=10).to(device)\n",
        "model_batch_norm = ResNet10(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop for ResNet-10 without regularization with early stopping\n",
        "optimizer_no_regularization = optim.Adam(model_no_regularization.parameters(), lr=0.001, weight_decay=0)\n",
        "train_and_evaluate(model_no_regularization, criterion, optimizer_no_regularization, num_epochs=300, regularization_name=\"No Regularization\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 without regularization for 100 epochs\n",
        "optimizer_no_regularization = optim.Adam(model_no_regularization.parameters(), lr=0.001, weight_decay=0)\n",
        "train_and_evaluate(model_no_regularization, criterion, optimizer_no_regularization, num_epochs=300, regularization_name=\"No Regularization\")\n",
        "\n",
        "# Training loop for ResNet-10 with Weight Decay (L2 regularization) with early stopping\n",
        "optimizer_weight_decay = optim.Adam(model_weight_decay.parameters(), lr=0.001, weight_decay=0.001)\n",
        "train_and_evaluate(model_weight_decay, criterion, optimizer_weight_decay, num_epochs=300, regularization_name=\"Weight Decay\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 with Dropout with early stopping\n",
        "model_dropout.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 10))  # Add dropout to the fully connected layer\n",
        "optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=0.001)\n",
        "train_and_evaluate(model_dropout, criterion, optimizer_dropout, num_epochs=300, regularization_name=\"Dropout\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 with Batch Normalization with early stopping\n",
        "optimizer_batch_norm = optim.Adam(model_batch_norm.parameters(), lr=0.001)\n",
        "train_and_evaluate(model_batch_norm, criterion, optimizer_batch_norm, num_epochs=300, regularization_name=\"Batch Normalization\", early_stop_threshold=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clyH8BUctbad",
        "outputId": "dfa46e86-602c-494c-a2b2-1d0a92cac708"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 77011744.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training ResNet-10 with No Regularization regularization:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Loss: 1.2863207671343517\n",
            "Validation Loss: 1.125054174547742\n",
            "Epoch 2/300, Loss: 0.9100795724355352\n",
            "Validation Loss: 0.9267733343847239\n",
            "Epoch 3/300, Loss: 0.7493533038193613\n",
            "Validation Loss: 0.815650786563849\n",
            "Epoch 4/300, Loss: 0.6432233471852129\n",
            "Validation Loss: 0.6873523572068305\n",
            "Epoch 5/300, Loss: 0.5686703488573699\n",
            "Validation Loss: 0.6592048192100161\n",
            "Epoch 6/300, Loss: 0.5094161417211414\n",
            "Validation Loss: 0.617073956378706\n",
            "Epoch 7/300, Loss: 0.4620920832047377\n",
            "Validation Loss: 0.6377087274364605\n",
            "Epoch 8/300, Loss: 0.4161109011953749\n",
            "Validation Loss: 0.7349901172765501\n",
            "Epoch 9/300, Loss: 0.3782496522835758\n",
            "Validation Loss: 0.689163667001542\n",
            "Epoch 10/300, Loss: 0.3477563195197326\n",
            "Validation Loss: 0.6302216660444904\n",
            "Epoch 11/300, Loss: 0.3103035500516062\n",
            "Validation Loss: 0.6360743996823669\n",
            "Early stopping at epoch 11 as validation loss did not improve for 5 epochs.\n",
            "Training Time: 300 epochs, Accuracy: 0.7985\n",
            "\n",
            "Training ResNet-10 with No Regularization regularization:\n",
            "Epoch 1/300, Loss: 0.28662122321098354\n",
            "Validation Loss: 0.614609115157917\n",
            "Epoch 2/300, Loss: 0.2478880062985146\n",
            "Validation Loss: 0.6622149411849915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIEyYYUdACfs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZLN2aSkCb1AVZ7WW9zbDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}