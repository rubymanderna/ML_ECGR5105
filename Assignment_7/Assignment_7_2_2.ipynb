{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubymanderna/ML_ECGR5105/blob/main/Assignment_7/Assignment_7_2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXXCeAzQjQd1"
      },
      "source": [
        "Problem 2 (50pts)\n",
        "a. Build a ResNet-based Convolutional Neural Network, like what we built in lectures (with skip connections), to classify the images across all 10 classes in CIFAR 10. For this problem, let's use 10 blocks for ResNet and call it ResNet-10. Use similar dimensions and channels as we need in lectures.\n",
        "Train your network for 300 epochs. Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against problem 1.b on training time, achieved accuracy, and model size.\n",
        "Make sure to submit your code by providing the GitHub URL of your course repository for this course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqcojEtqhdCR",
        "outputId": "67eeb931-10c6-482b-ad5c-d2f408460e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300, Loss: 1.2852477739229227\n",
            "Epoch 2/300, Loss: 0.9028657511676974\n",
            "Epoch 3/300, Loss: 0.7466733924415715\n",
            "Epoch 4/300, Loss: 0.6394158432931851\n",
            "Epoch 5/300, Loss: 0.5632952336612564\n",
            "Epoch 6/300, Loss: 0.5033765495623774\n",
            "Epoch 7/300, Loss: 0.44811864953745356\n",
            "Epoch 8/300, Loss: 0.4103087388226748\n",
            "Epoch 9/300, Loss: 0.369368021731334\n",
            "Epoch 10/300, Loss: 0.331803418781675\n",
            "Epoch 11/300, Loss: 0.2937268433172989\n",
            "Epoch 12/300, Loss: 0.2634619428583271\n",
            "Epoch 13/300, Loss: 0.23740033436652339\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # Define the Residual Block\n",
        "# class ResidualBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, stride=1):\n",
        "#         super(ResidualBlock, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "#         self.downsample = nn.Sequential()\n",
        "#         if stride != 1 or in_channels != out_channels:\n",
        "#             self.downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels)\n",
        "#             )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "#         out += self.downsample(identity)\n",
        "#         out = self.relu(out)\n",
        "#         return out\n",
        "\n",
        "# # Define the ResNet-10 architecture\n",
        "# class ResNet10(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(ResNet10, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(16)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.layer1 = self.make_layer(16, 16, num_blocks=2, stride=1)\n",
        "#         self.layer2 = self.make_layer(16, 32, num_blocks=2, stride=2)\n",
        "#         self.layer3 = self.make_layer(32, 64, num_blocks=2, stride=2)\n",
        "#         self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "#     def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "#         layers = []\n",
        "#         layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "#         for _ in range(1, num_blocks):\n",
        "#             layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.avg_pool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# # Set the device (GPU if available, otherwise CPU)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Load CIFAR-10 dataset\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "# ])\n",
        "\n",
        "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "# # Initialize the ResNet-10 model, loss function, and optimizer\n",
        "# model = ResNet10(num_classes=10).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # Training loop\n",
        "# num_epochs = 30\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     total_loss = 0.0\n",
        "#     for inputs, labels in train_loader:\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# # Evaluation\n",
        "# model.eval()\n",
        "# correct = 0\n",
        "# total = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in test_loader:\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         outputs = model(inputs)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# accuracy = correct / total\n",
        "# print(f\"Training Time: {num_epochs} epochs, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljw29pkFjPn-"
      },
      "source": [
        ". Perform three additional training and evaluations for your ResNet-10 to assess the impacts of regularization on your ResNet-10.\n",
        "* ﻿﻿Weight Decay with lambda of 0.001\n",
        "* ﻿﻿Dropout with p=0.3\n",
        "* ﻿﻿Batch Normalization\n",
        "Report and compare your training time, training loss, and evaluation accuracy after 300 epochs across these three different pieces of training.\n",
        "Analyze your results in your report and compare them against problem 1. On training time, you achieved accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the Residual Block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.downsample(identity)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet-10 architecture\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(16, 16, num_blocks=2, stride=1)\n",
        "        self.layer2 = self.make_layer(16, 32, num_blocks=2, stride=2)\n",
        "        self.layer3 = self.make_layer(32, 64, num_blocks=2, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "# Function to train and evaluate the model with early stopping\n",
        "def train_and_evaluate(model, criterion, optimizer, num_epochs=3, regularization_name=\"None\", early_stop_threshold=5):\n",
        "    print(f\"Training ResNet-10 with {regularization_name} regularization:\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        print(f\"Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == early_stop_threshold:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} as validation loss did not improve for {early_stop_threshold} epochs.\")\n",
        "            break\n",
        "\n",
        "    # Evaluation (unchanged)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Training Time: {num_epochs} epochs, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Initialize the ResNet-10 model, loss function, and optimizer for each scenario\n",
        "model_no_regularization = ResNet10(num_classes=10).to(device)\n",
        "model_weight_decay = ResNet10(num_classes=10).to(device)\n",
        "model_dropout = ResNet10(num_classes=10).to(device)\n",
        "model_batch_norm = ResNet10(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop for ResNet-10 without regularization with early stopping\n",
        "optimizer_no_regularization = optim.Adam(model_no_regularization.parameters(), lr=0.001, weight_decay=0)\n",
        "train_and_evaluate(model_no_regularization, criterion, optimizer_no_regularization, num_epochs=300, regularization_name=\"No Regularization\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 without regularization for 100 epochs\n",
        "optimizer_no_regularization = optim.Adam(model_no_regularization.parameters(), lr=0.001, weight_decay=0)\n",
        "train_and_evaluate(model_no_regularization, criterion, optimizer_no_regularization, num_epochs=300, regularization_name=\"No Regularization\")\n",
        "\n",
        "# Training loop for ResNet-10 with Weight Decay (L2 regularization) with early stopping\n",
        "optimizer_weight_decay = optim.Adam(model_weight_decay.parameters(), lr=0.001, weight_decay=0.001)\n",
        "train_and_evaluate(model_weight_decay, criterion, optimizer_weight_decay, num_epochs=300, regularization_name=\"Weight Decay\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 with Dropout with early stopping\n",
        "model_dropout.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 10))  # Add dropout to the fully connected layer\n",
        "optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=0.001)\n",
        "train_and_evaluate(model_dropout, criterion, optimizer_dropout, num_epochs=300, regularization_name=\"Dropout\", early_stop_threshold=5)\n",
        "\n",
        "# Training loop for ResNet-10 with Batch Normalization with early stopping\n",
        "optimizer_batch_norm = optim.Adam(model_batch_norm.parameters(), lr=0.001)\n",
        "train_and_evaluate(model_batch_norm, criterion, optimizer_batch_norm, num_epochs=300, regularization_name=\"Batch Normalization\", early_stop_threshold=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clyH8BUctbad",
        "outputId": "4cbdc517-8d69-4c78-8b10-89b628ff67f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 77011744.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training ResNet-10 with No Regularization regularization:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.2863207671343517\n",
            "Validation Loss: 1.125054174547742\n",
            "Epoch 2/300, Loss: 0.9100795724355352\n",
            "Validation Loss: 0.9267733343847239\n",
            "Epoch 3/300, Loss: 0.7493533038193613\n",
            "Validation Loss: 0.815650786563849\n",
            "Epoch 4/300, Loss: 0.6432233471852129\n",
            "Validation Loss: 0.6873523572068305\n",
            "Epoch 5/300, Loss: 0.5686703488573699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnBLv-GejmL_",
        "outputId": "faefb51c-8889-4185-bc45-a5046d460ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 103562774.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Training ResNet-10 with No Regularization regularization:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Loss: 1.3222510517405732\n",
            "Epoch 2/3, Loss: 0.920783624014891\n",
            "Epoch 3/3, Loss: 0.7573221164667393\n",
            "Training Time: 3 epochs, Accuracy: 0.7371\n",
            "\n",
            "Training ResNet-10 with Weight Decay regularization:\n",
            "Epoch 1/3, Loss: 1.3316854136374296\n",
            "Epoch 2/3, Loss: 0.9283693502931034\n",
            "Epoch 3/3, Loss: 0.7750959259546016\n",
            "Training Time: 3 epochs, Accuracy: 0.7028\n",
            "\n",
            "Training ResNet-10 with Dropout regularization:\n",
            "Epoch 1/3, Loss: 1.4200914576840218\n",
            "Epoch 2/3, Loss: 1.020251123344197\n",
            "Epoch 3/3, Loss: 0.8624663820961858\n",
            "Training Time: 3 epochs, Accuracy: 0.6963\n",
            "\n",
            "Training ResNet-10 with Batch Normalization regularization:\n",
            "Epoch 1/3, Loss: 1.3134789274781562\n",
            "Epoch 2/3, Loss: 0.9023827093336588\n",
            "Epoch 3/3, Loss: 0.7424944091940779\n",
            "Training Time: 3 epochs, Accuracy: 0.6945\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # Define the Residual Block\n",
        "# class ResidualBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, stride=1):\n",
        "#         super(ResidualBlock, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "#         self.downsample = nn.Sequential()\n",
        "#         if stride != 1 or in_channels != out_channels:\n",
        "#             self.downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels)\n",
        "#             )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "#         out += self.downsample(identity)\n",
        "#         out = self.relu(out)\n",
        "#         return out\n",
        "\n",
        "# # Define the ResNet-10 architecture\n",
        "# class ResNet10(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(ResNet10, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(16)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.layer1 = self.make_layer(16, 16, num_blocks=2, stride=1)\n",
        "#         self.layer2 = self.make_layer(16, 32, num_blocks=2, stride=2)\n",
        "#         self.layer3 = self.make_layer(32, 64, num_blocks=2, stride=2)\n",
        "#         self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "#     def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "#         layers = []\n",
        "#         layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "#         for _ in range(1, num_blocks):\n",
        "#             layers.append(ResidualBlock(out_channels, out_channels, stride=1))\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.avg_pool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# # Set the device (GPU if available, otherwise CPU)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Load CIFAR-10 dataset\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "# ])\n",
        "\n",
        "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "# # Function to train and evaluate the model\n",
        "# def train_and_evaluate(model, criterion, optimizer, num_epochs=3, regularization_name=\"None\"):\n",
        "#     print(f\"Training ResNet-10 with {regularization_name} regularization:\")\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         model.train()\n",
        "#         total_loss = 0.0\n",
        "#         for inputs, labels in train_loader:\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item()\n",
        "\n",
        "#         print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "#     model.eval()\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in test_loader:\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "#             outputs = model(inputs)\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             total += labels.size(0)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     accuracy = correct / total\n",
        "#     print(f\"Training Time: {num_epochs} epochs, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# # Initialize the ResNet-10 model, loss function, and optimizer for each scenario\n",
        "# model_no_regularization = ResNet10(num_classes=10).to(device)\n",
        "# model_weight_decay = ResNet10(num_classes=10).to(device)\n",
        "# model_dropout = ResNet10(num_classes=10).to(device)\n",
        "# model_batch_norm = ResNet10(num_classes=10).to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # Training loop for ResNet-10 without regularization for 100 epochs\n",
        "# optimizer_no_regularization = optim.Adam(model_no_regularization.parameters(), lr=0.001, weight_decay=0)\n",
        "# train_and_evaluate(model_no_regularization, criterion, optimizer_no_regularization, num_epochs=3, regularization_name=\"No Regularization\")\n",
        "\n",
        "# # Training loop for ResNet-10 with Weight Decay (L2 regularization) for 100 epochs\n",
        "# optimizer_weight_decay = optim.Adam(model_weight_decay.parameters(), lr=0.001, weight_decay=0.001)\n",
        "# train_and_evaluate(model_weight_decay, criterion, optimizer_weight_decay, num_epochs=3, regularization_name=\"Weight Decay\")\n",
        "\n",
        "# # Training loop for ResNet-10 with Dropout for 100 epochs\n",
        "# model_dropout.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 10))  # Add dropout to the fully connected layer\n",
        "# optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=0.001)\n",
        "# train_and_evaluate(model_dropout, criterion, optimizer_dropout, num_epochs=3, regularization_name=\"Dropout\")\n",
        "\n",
        "# # Training loop for ResNet-10 with Batch Normalization for 100 epochs\n",
        "# optimizer_batch_norm = optim.Adam(model_batch_norm.parameters(), lr=0.001)\n",
        "# train_and_evaluate(model_batch_norm, criterion, optimizer_batch_norm, num_epochs=3, regularization_name=\"Batch Normalization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIEyYYUdACfs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEj6pAnSfMyjEZztJxuwNL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}